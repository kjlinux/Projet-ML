{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et Modélisation des Données de Facturation d'Eau\n",
    "\n",
    "## Objectifs du Projet\n",
    "- Analyser les données de facturation d'eau\n",
    "- Prédire les catégories de clients\n",
    "- Prédire les résiliations\n",
    "- Prédire les montants de facturation\n",
    "- Utiliser des techniques robustes pour éviter le surapprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "\n",
    "# Modèles de Classification\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, AdaBoostClassifier, \n",
    "    GradientBoostingClassifier, BaggingClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Modèles de Régression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, AdaBoostRegressor, \n",
    "    GradientBoostingRegressor, BaggingRegressor\n",
    ")\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Gestion du déséquilibre\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Bibliothèques importées avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les noms de colonnes\n",
    "colonnes = [\n",
    "    'DR', 'CEN', 'POLICE', 'O', 'P', 'ENR', 'MM', 'AAAA', 'DATE_FACT', \n",
    "    'DIAM', 'CUBCONS', 'CUBFAC', 'FORFAIT', 'SOCIAL', 'DOMEST', 'NORMAL', \n",
    "    'INDUST', 'ADMINI', 'MONT_SOD', 'MONT_TVA', 'MONT_FDE', 'MONT_FNE', \n",
    "    'MONT_ASS_TTC', 'MONT_FRAIS_CPT', 'MONT_TTC', 'DATE_ABON', 'DATE_RESIL', \n",
    "    'TOURNEE', 'DATE_REGLT', 'AAENC', 'MMENC', 'RESILIE', 'CATEGORIE', \n",
    "    'NOUVEAU', 'DATE_REGLT_ENC'\n",
    "]\n",
    "\n",
    "# Charger tous les fichiers .txt du dossier datasets\n",
    "chemin_datasets = 'datasets/*.txt'\n",
    "fichiers = glob.glob(chemin_datasets)\n",
    "\n",
    "print(f\"Nombre de fichiers trouvés: {len(fichiers)}\")\n",
    "print(\"Fichiers:\", fichiers)\n",
    "\n",
    "# Liste pour stocker les dataframes\n",
    "liste_df = []\n",
    "\n",
    "# Charger chaque fichier\n",
    "for fichier in fichiers:\n",
    "    try:\n",
    "        df_temp = pd.read_csv(\n",
    "            fichier, \n",
    "            sep=',',\n",
    "            names=colonnes,\n",
    "            encoding='utf-8',\n",
    "            low_memory=False\n",
    "        )\n",
    "        liste_df.append(df_temp)\n",
    "        print(f\"Chargé: {fichier} - {len(df_temp)} lignes\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de {fichier}: {e}\")\n",
    "\n",
    "# Concaténer tous les dataframes\n",
    "if liste_df:\n",
    "    df = pd.concat(liste_df, ignore_index=True)\n",
    "    print(f\"\\nDataframe final: {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "else:\n",
    "    print(\"Aucune donnée chargée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des premières lignes\n",
    "print(\"Aperçu des données:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur les données\n",
    "print(\"Informations sur le dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(\"Statistiques descriptives:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "valeurs_manquantes = df.isnull().sum()\n",
    "pourcentage_manquant = (valeurs_manquantes / len(df)) * 100\n",
    "resume_manquant = pd.DataFrame({\n",
    "    'Nombre_Manquant': valeurs_manquantes,\n",
    "    'Pourcentage': pourcentage_manquant\n",
    "})\n",
    "print(resume_manquant[resume_manquant['Nombre_Manquant'] > 0].sort_values('Pourcentage', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des catégories\n",
    "print(\"Distribution des catégories de clients:\")\n",
    "print(df['CATEGORIE'].value_counts())\n",
    "\n",
    "print(\"\\nDistribution des résiliations:\")\n",
    "print(df['RESILIE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution des catégories\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Distribution des catégories\n",
    "df['CATEGORIE'].value_counts().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Distribution des Catégories de Clients', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Catégorie')\n",
    "axes[0].set_ylabel('Nombre de factures')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Distribution des résiliations\n",
    "df['RESILIE'].value_counts().plot(kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Distribution des Résiliations', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Résilié (1=Oui, 0=Non)')\n",
    "axes[1].set_ylabel('Nombre de factures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une copie pour le traitement\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Convertir les colonnes de dates\n",
    "colonnes_dates = ['DATE_FACT', 'DATE_ABON', 'DATE_RESIL', 'DATE_REGLT', 'DATE_REGLT_ENC']\n",
    "\n",
    "for col in colonnes_dates:\n",
    "    try:\n",
    "        df_processed[col] = pd.to_datetime(df_processed[col], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion de {col}: {e}\")\n",
    "\n",
    "print(\"Colonnes de dates converties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des features temporelles\n",
    "if pd.api.types.is_datetime64_any_dtype(df_processed['DATE_FACT']):\n",
    "    df_processed['ANNEE_FACT'] = df_processed['DATE_FACT'].dt.year\n",
    "    df_processed['MOIS_FACT'] = df_processed['DATE_FACT'].dt.month\n",
    "    df_processed['TRIMESTRE_FACT'] = df_processed['DATE_FACT'].dt.quarter\n",
    "    \n",
    "# Calculer le délai de paiement (en jours)\n",
    "if pd.api.types.is_datetime64_any_dtype(df_processed['DATE_REGLT']) and \\\n",
    "   pd.api.types.is_datetime64_any_dtype(df_processed['DATE_FACT']):\n",
    "    df_processed['DELAI_PAIEMENT'] = (\n",
    "        df_processed['DATE_REGLT'] - df_processed['DATE_FACT']\n",
    "    ).dt.days\n",
    "    \n",
    "# Calculer la durée d'abonnement (en jours)\n",
    "if pd.api.types.is_datetime64_any_dtype(df_processed['DATE_FACT']) and \\\n",
    "   pd.api.types.is_datetime64_any_dtype(df_processed['DATE_ABON']):\n",
    "    df_processed['DUREE_ABONNEMENT'] = (\n",
    "        df_processed['DATE_FACT'] - df_processed['DATE_ABON']\n",
    "    ).dt.days\n",
    "\n",
    "print(\"Features temporelles créées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des features supplémentaires\n",
    "# Ratio consommation/facturation\n",
    "df_processed['RATIO_CONS_FAC'] = df_processed['CUBCONS'] / (df_processed['CUBFAC'] + 1)\n",
    "\n",
    "# Prix unitaire\n",
    "df_processed['PRIX_UNITAIRE'] = df_processed['MONT_TTC'] / (df_processed['CUBFAC'] + 1)\n",
    "\n",
    "# Somme des consommations par type\n",
    "df_processed['TOTAL_CONS_TYPE'] = (\n",
    "    df_processed['SOCIAL'] + df_processed['DOMEST'] + \n",
    "    df_processed['NORMAL'] + df_processed['INDUST'] + df_processed['ADMINI']\n",
    ")\n",
    "\n",
    "# Type dominant de consommation\n",
    "df_processed['TYPE_DOMINANT'] = df_processed[\n",
    "    ['SOCIAL', 'DOMEST', 'NORMAL', 'INDUST', 'ADMINI']\n",
    "].idxmax(axis=1)\n",
    "\n",
    "print(\"Features supplémentaires créées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gérer les valeurs infinies et aberrantes\n",
    "df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Remplir les valeurs manquantes numériques par la médiane\n",
    "colonnes_numeriques = df_processed.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in colonnes_numeriques:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        mediane = df_processed[col].median()\n",
    "        df_processed[col].fillna(mediane, inplace=True)\n",
    "        \n",
    "print(\"Valeurs manquantes traitées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les variables catégorielles\n",
    "le_categorie = LabelEncoder()\n",
    "le_type_dominant = LabelEncoder()\n",
    "le_mmenc = LabelEncoder()\n",
    "\n",
    "df_processed['CATEGORIE_ENCODED'] = le_categorie.fit_transform(df_processed['CATEGORIE'].astype(str))\n",
    "df_processed['TYPE_DOMINANT_ENCODED'] = le_type_dominant.fit_transform(df_processed['TYPE_DOMINANT'].astype(str))\n",
    "df_processed['MMENC_ENCODED'] = le_mmenc.fit_transform(df_processed['MMENC'].astype(str))\n",
    "\n",
    "print(\"Variables catégorielles encodées\")\n",
    "print(f\"Catégories: {list(le_categorie.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse Exploratoire Visuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la consommation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Consommation par catégorie\n",
    "df_processed.boxplot(column='CUBCONS', by='CATEGORIE', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribution de la Consommation par Catégorie', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Catégorie')\n",
    "axes[0, 0].set_ylabel('Consommation (m3)')\n",
    "\n",
    "# Montant TTC par catégorie\n",
    "df_processed.boxplot(column='MONT_TTC', by='CATEGORIE', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Distribution du Montant TTC par Catégorie', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Catégorie')\n",
    "axes[0, 1].set_ylabel('Montant TTC')\n",
    "\n",
    "# Consommation par type dominant\n",
    "df_processed.boxplot(column='CUBCONS', by='TYPE_DOMINANT', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribution de la Consommation par Type Dominant', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Type Dominant')\n",
    "axes[1, 0].set_ylabel('Consommation (m3)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Délai de paiement par catégorie\n",
    "if 'DELAI_PAIEMENT' in df_processed.columns:\n",
    "    df_processed.boxplot(column='DELAI_PAIEMENT', by='CATEGORIE', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Distribution du Délai de Paiement par Catégorie', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Catégorie')\n",
    "    axes[1, 1].set_ylabel('Délai de Paiement (jours)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation des variables numériques principales\n",
    "colonnes_correlation = [\n",
    "    'CUBCONS', 'CUBFAC', 'SOCIAL', 'DOMEST', 'NORMAL', 'INDUST', 'ADMINI',\n",
    "    'MONT_SOD', 'MONT_TVA', 'MONT_TTC', 'DELAI_PAIEMENT', 'PRIX_UNITAIRE'\n",
    "]\n",
    "\n",
    "colonnes_disponibles = [col for col in colonnes_correlation if col in df_processed.columns]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "matrice_corr = df_processed[colonnes_disponibles].corr()\n",
    "sns.heatmap(matrice_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matrice de Corrélation des Variables Principales', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Préparation des Données pour la Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les features pour la modélisation\n",
    "features_base = [\n",
    "    'DR', 'CEN', 'POLICE', 'O', 'P', 'DIAM', 'CUBCONS', 'CUBFAC', \n",
    "    'FORFAIT', 'SOCIAL', 'DOMEST', 'NORMAL', 'INDUST', 'ADMINI',\n",
    "    'MONT_SOD', 'MONT_TVA', 'MONT_FDE', 'MONT_FNE', \n",
    "    'TOURNEE', 'AAAA', 'MM'\n",
    "]\n",
    "\n",
    "features_engineered = [\n",
    "    'RATIO_CONS_FAC', 'PRIX_UNITAIRE', 'TOTAL_CONS_TYPE',\n",
    "    'TYPE_DOMINANT_ENCODED', 'MMENC_ENCODED'\n",
    "]\n",
    "\n",
    "if 'DELAI_PAIEMENT' in df_processed.columns:\n",
    "    features_engineered.append('DELAI_PAIEMENT')\n",
    "if 'DUREE_ABONNEMENT' in df_processed.columns:\n",
    "    features_engineered.append('DUREE_ABONNEMENT')\n",
    "if 'ANNEE_FACT' in df_processed.columns:\n",
    "    features_engineered.append('ANNEE_FACT')\n",
    "if 'MOIS_FACT' in df_processed.columns:\n",
    "    features_engineered.append('MOIS_FACT')\n",
    "if 'TRIMESTRE_FACT' in df_processed.columns:\n",
    "    features_engineered.append('TRIMESTRE_FACT')\n",
    "\n",
    "# Combiner toutes les features\n",
    "all_features = features_base + features_engineered\n",
    "\n",
    "# Vérifier que toutes les features existent\n",
    "features_finales = [f for f in all_features if f in df_processed.columns]\n",
    "\n",
    "print(f\"Nombre de features sélectionnées: {len(features_finales)}\")\n",
    "print(f\"Features: {features_finales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modélisation - Prédiction de la Catégorie de Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour la classification de catégorie\n",
    "X_categorie = df_processed[features_finales].copy()\n",
    "y_categorie = df_processed['CATEGORIE_ENCODED'].copy()\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "mask = ~(X_categorie.isnull().any(axis=1) | y_categorie.isnull())\n",
    "X_categorie = X_categorie[mask]\n",
    "y_categorie = y_categorie[mask]\n",
    "\n",
    "print(f\"Taille du dataset pour la classification: {X_categorie.shape}\")\n",
    "print(f\"Distribution des classes:\")\n",
    "print(y_categorie.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test stratifié\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "    X_categorie, y_categorie, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_categorie\n",
    ")\n",
    "\n",
    "print(f\"Taille train: {X_train_cat.shape}\")\n",
    "print(f\"Taille test: {X_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features\n",
    "scaler_cat = StandardScaler()\n",
    "X_train_cat_scaled = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_scaled = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "print(\"Features normalisées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles de classification avec techniques anti-surapprentissage\n",
    "modeles_classification = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=3),\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Bagging': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=10),\n",
    "        n_estimators=50,\n",
    "        max_samples=0.8,\n",
    "        max_features=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Logistic Regression (L2)': LogisticRegression(\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Modèles de classification définis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner et évaluer chaque modèle avec validation croisée\n",
    "resultats_classification = {}\n",
    "cv_scores = {}\n",
    "\n",
    "print(\"Entraînement des modèles de classification...\\n\")\n",
    "\n",
    "for nom, modele in modeles_classification.items():\n",
    "    print(f\"Entraînement du modèle: {nom}\")\n",
    "    \n",
    "    # Validation croisée stratifiée\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_score = cross_val_score(\n",
    "        modele, \n",
    "        X_train_cat_scaled, \n",
    "        y_train_cat, \n",
    "        cv=skf, \n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    modele.fit(X_train_cat_scaled, y_train_cat)\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred_train = modele.predict(X_train_cat_scaled)\n",
    "    y_pred_test = modele.predict(X_test_cat_scaled)\n",
    "    \n",
    "    # Scores\n",
    "    train_score = accuracy_score(y_train_cat, y_pred_train)\n",
    "    test_score = accuracy_score(y_test_cat, y_pred_test)\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    resultats_classification[nom] = {\n",
    "        'modele': modele,\n",
    "        'train_score': train_score,\n",
    "        'test_score': test_score,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    cv_scores[nom] = cv_score\n",
    "    \n",
    "    print(f\"Score CV (mean ± std): {cv_score.mean():.4f} ± {cv_score.std():.4f}\")\n",
    "    print(f\"Score Train: {train_score:.4f}\")\n",
    "    print(f\"Score Test: {test_score:.4f}\")\n",
    "    print(f\"Différence Train-Test: {abs(train_score - test_score):.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les performances des modèles\n",
    "comparaison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Modèle': nom,\n",
    "        'Score CV (mean)': cv_scores[nom].mean(),\n",
    "        'Score CV (std)': cv_scores[nom].std(),\n",
    "        'Score Train': res['train_score'],\n",
    "        'Score Test': res['test_score'],\n",
    "        'Surapprentissage': abs(res['train_score'] - res['test_score'])\n",
    "    }\n",
    "    for nom, res in resultats_classification.items()\n",
    "]).sort_values('Score Test', ascending=False)\n",
    "\n",
    "print(\"Comparaison des modèles de classification:\")\n",
    "print(comparaison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la comparaison des modèles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scores de test\n",
    "comparaison_df.plot(x='Modèle', y='Score Test', kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Scores de Test par Modèle', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].axhline(y=comparaison_df['Score Test'].max(), color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Surapprentissage\n",
    "comparaison_df.plot(x='Modèle', y='Surapprentissage', kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Niveau de Surapprentissage par Modèle', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Différence Train-Test')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner le meilleur modèle\n",
    "meilleur_modele_nom = comparaison_df.iloc[0]['Modèle']\n",
    "meilleur_modele_cat = resultats_classification[meilleur_modele_nom]['modele']\n",
    "\n",
    "print(f\"Meilleur modèle: {meilleur_modele_nom}\")\n",
    "print(f\"Score Test: {comparaison_df.iloc[0]['Score Test']:.4f}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "y_pred_meilleur = resultats_classification[meilleur_modele_nom]['y_pred_test']\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(\n",
    "    y_test_cat, \n",
    "    y_pred_meilleur, \n",
    "    target_names=[str(c) for c in le_categorie.classes_]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test_cat, y_pred_meilleur)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_categorie.classes_,\n",
    "            yticklabels=le_categorie.classes_)\n",
    "plt.title(f'Matrice de Confusion - {meilleur_modele_nom}', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Vraie Catégorie')\n",
    "plt.xlabel('Catégorie Prédite')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance pour les modèles basés sur les arbres\n",
    "if hasattr(meilleur_modele_cat, 'feature_importances_'):\n",
    "    importances = meilleur_modele_cat.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:20]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(indices)), importances[indices], color='teal')\n",
    "    plt.yticks(range(len(indices)), [features_finales[i] for i in indices])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 20 Features Importantes - {meilleur_modele_nom}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modélisation - Prédiction des Résiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour la prédiction de résiliation\n",
    "X_resil = df_processed[features_finales].copy()\n",
    "y_resil = df_processed['RESILIE'].copy()\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "mask = ~(X_resil.isnull().any(axis=1) | y_resil.isnull())\n",
    "X_resil = X_resil[mask]\n",
    "y_resil = y_resil[mask]\n",
    "\n",
    "print(f\"Taille du dataset pour la prédiction de résiliation: {X_resil.shape}\")\n",
    "print(f\"Distribution des classes:\")\n",
    "print(y_resil.value_counts())\n",
    "print(f\"Pourcentage de résiliations: {(y_resil.sum() / len(y_resil)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test stratifié\n",
    "X_train_resil, X_test_resil, y_train_resil, y_test_resil = train_test_split(\n",
    "    X_resil, y_resil, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_resil\n",
    ")\n",
    "\n",
    "# Normalisation\n",
    "scaler_resil = StandardScaler()\n",
    "X_train_resil_scaled = scaler_resil.fit_transform(X_train_resil)\n",
    "X_test_resil_scaled = scaler_resil.transform(X_test_resil)\n",
    "\n",
    "print(f\"Taille train: {X_train_resil.shape}\")\n",
    "print(f\"Taille test: {X_test_resil.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gérer le déséquilibre de classes avec SMOTE\n",
    "print(\"Application de SMOTE pour équilibrer les classes...\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resil_balanced, y_train_resil_balanced = smote.fit_resample(\n",
    "    X_train_resil_scaled, \n",
    "    y_train_resil\n",
    ")\n",
    "\n",
    "print(f\"Taille après SMOTE: {X_train_resil_balanced.shape}\")\n",
    "print(f\"Distribution après SMOTE:\")\n",
    "print(pd.Series(y_train_resil_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner et évaluer les modèles pour la résiliation\n",
    "resultats_resiliation = {}\n",
    "cv_scores_resil = {}\n",
    "\n",
    "print(\"Entraînement des modèles de prédiction de résiliation...\\n\")\n",
    "\n",
    "for nom, modele in modeles_classification.items():\n",
    "    print(f\"Entraînement du modèle: {nom}\")\n",
    "    \n",
    "    # Validation croisée\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_score = cross_val_score(\n",
    "        modele, \n",
    "        X_train_resil_balanced, \n",
    "        y_train_resil_balanced, \n",
    "        cv=skf, \n",
    "        scoring='roc_auc'\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    modele.fit(X_train_resil_balanced, y_train_resil_balanced)\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred_train = modele.predict(X_train_resil_balanced)\n",
    "    y_pred_test = modele.predict(X_test_resil_scaled)\n",
    "    \n",
    "    # Scores\n",
    "    train_score = accuracy_score(y_train_resil_balanced, y_pred_train)\n",
    "    test_score = accuracy_score(y_test_resil, y_pred_test)\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    resultats_resiliation[nom] = {\n",
    "        'modele': modele,\n",
    "        'train_score': train_score,\n",
    "        'test_score': test_score,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    cv_scores_resil[nom] = cv_score\n",
    "    \n",
    "    print(f\"Score CV ROC-AUC (mean ± std): {cv_score.mean():.4f} ± {cv_score.std():.4f}\")\n",
    "    print(f\"Score Train: {train_score:.4f}\")\n",
    "    print(f\"Score Test: {test_score:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les performances pour la résiliation\n",
    "comparaison_resil_df = pd.DataFrame([\n",
    "    {\n",
    "        'Modèle': nom,\n",
    "        'Score CV ROC-AUC (mean)': cv_scores_resil[nom].mean(),\n",
    "        'Score CV ROC-AUC (std)': cv_scores_resil[nom].std(),\n",
    "        'Score Train': res['train_score'],\n",
    "        'Score Test': res['test_score']\n",
    "    }\n",
    "    for nom, res in resultats_resiliation.items()\n",
    "]).sort_values('Score Test', ascending=False)\n",
    "\n",
    "print(\"Comparaison des modèles pour la prédiction de résiliation:\")\n",
    "print(comparaison_resil_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur modèle pour la résiliation\n",
    "meilleur_modele_resil_nom = comparaison_resil_df.iloc[0]['Modèle']\n",
    "meilleur_modele_resil = resultats_resiliation[meilleur_modele_resil_nom]['modele']\n",
    "y_pred_resil_meilleur = resultats_resiliation[meilleur_modele_resil_nom]['y_pred_test']\n",
    "\n",
    "print(f\"Meilleur modèle pour la résiliation: {meilleur_modele_resil_nom}\")\n",
    "print(f\"Score Test: {comparaison_resil_df.iloc[0]['Score Test']:.4f}\")\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(y_test_resil, y_pred_resil_meilleur, \n",
    "                          target_names=['Non Résilié', 'Résilié']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la résiliation\n",
    "cm_resil = confusion_matrix(y_test_resil, y_pred_resil_meilleur)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_resil, annot=True, fmt='d', cmap='Reds',\n",
    "            xticklabels=['Non Résilié', 'Résilié'],\n",
    "            yticklabels=['Non Résilié', 'Résilié'])\n",
    "plt.title(f'Matrice de Confusion - Résiliation - {meilleur_modele_resil_nom}', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Vraie Classe')\n",
    "plt.xlabel('Classe Prédite')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Modélisation - Prédiction du Montant TTC (Régression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour la régression\n",
    "features_regression = [f for f in features_finales if f != 'MONT_TTC']\n",
    "\n",
    "X_reg = df_processed[features_regression].copy()\n",
    "y_reg = df_processed['MONT_TTC'].copy()\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "mask = ~(X_reg.isnull().any(axis=1) | y_reg.isnull())\n",
    "X_reg = X_reg[mask]\n",
    "y_reg = y_reg[mask]\n",
    "\n",
    "print(f\"Taille du dataset pour la régression: {X_reg.shape}\")\n",
    "print(f\"Statistiques de la variable cible (MONT_TTC):\")\n",
    "print(y_reg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Normalisation\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "print(f\"Taille train: {X_train_reg.shape}\")\n",
    "print(f\"Taille test: {X_test_reg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles de régression avec régularisation\n",
    "modeles_regression = {\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Ridge': Ridge(\n",
    "        alpha=1.0,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Lasso': Lasso(\n",
    "        alpha=1.0,\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    ),\n",
    "    'ElasticNet': ElasticNet(\n",
    "        alpha=1.0,\n",
    "        l1_ratio=0.5,\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Modèles de régression définis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner et évaluer les modèles de régression\n",
    "resultats_regression = {}\n",
    "cv_scores_reg = {}\n",
    "\n",
    "print(\"Entraînement des modèles de régression...\\n\")\n",
    "\n",
    "for nom, modele in modeles_regression.items():\n",
    "    print(f\"Entraînement du modèle: {nom}\")\n",
    "    \n",
    "    # Validation croisée\n",
    "    cv_score = cross_val_score(\n",
    "        modele, \n",
    "        X_train_reg_scaled, \n",
    "        y_train_reg, \n",
    "        cv=5, \n",
    "        scoring='r2'\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    modele.fit(X_train_reg_scaled, y_train_reg)\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred_train = modele.predict(X_train_reg_scaled)\n",
    "    y_pred_test = modele.predict(X_test_reg_scaled)\n",
    "    \n",
    "    # Métriques\n",
    "    train_r2 = r2_score(y_train_reg, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_reg, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_reg, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test_reg, y_pred_test)\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    resultats_regression[nom] = {\n",
    "        'modele': modele,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    cv_scores_reg[nom] = cv_score\n",
    "    \n",
    "    print(f\"Score CV R2 (mean ± std): {cv_score.mean():.4f} ± {cv_score.std():.4f}\")\n",
    "    print(f\"R2 Train: {train_r2:.4f}\")\n",
    "    print(f\"R2 Test: {test_r2:.4f}\")\n",
    "    print(f\"RMSE Train: {train_rmse:.2f}\")\n",
    "    print(f\"RMSE Test: {test_rmse:.2f}\")\n",
    "    print(f\"MAE Test: {test_mae:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les performances des modèles de régression\n",
    "comparaison_reg_df = pd.DataFrame([\n",
    "    {\n",
    "        'Modèle': nom,\n",
    "        'CV R2 (mean)': cv_scores_reg[nom].mean(),\n",
    "        'CV R2 (std)': cv_scores_reg[nom].std(),\n",
    "        'R2 Train': res['train_r2'],\n",
    "        'R2 Test': res['test_r2'],\n",
    "        'RMSE Test': res['test_rmse'],\n",
    "        'MAE Test': res['test_mae']\n",
    "    }\n",
    "    for nom, res in resultats_regression.items()\n",
    "]).sort_values('R2 Test', ascending=False)\n",
    "\n",
    "print(\"Comparaison des modèles de régression:\")\n",
    "print(comparaison_reg_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les performances des modèles de régression\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# R2 Score\n",
    "comparaison_reg_df.plot(x='Modèle', y=['R2 Train', 'R2 Test'], \n",
    "                       kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Scores R2 par Modèle', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('R2 Score')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].legend(['Train', 'Test'])\n",
    "\n",
    "# RMSE\n",
    "comparaison_reg_df.plot(x='Modèle', y='RMSE Test', kind='bar', \n",
    "                       ax=axes[1], color='coral')\n",
    "axes[1].set_title('RMSE Test par Modèle', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur modèle de régression\n",
    "meilleur_modele_reg_nom = comparaison_reg_df.iloc[0]['Modèle']\n",
    "meilleur_modele_reg = resultats_regression[meilleur_modele_reg_nom]['modele']\n",
    "y_pred_reg_meilleur = resultats_regression[meilleur_modele_reg_nom]['y_pred_test']\n",
    "\n",
    "print(f\"Meilleur modèle de régression: {meilleur_modele_reg_nom}\")\n",
    "print(f\"R2 Test: {comparaison_reg_df.iloc[0]['R2 Test']:.4f}\")\n",
    "print(f\"RMSE Test: {comparaison_reg_df.iloc[0]['RMSE Test']:.2f}\")\n",
    "print(f\"MAE Test: {comparaison_reg_df.iloc[0]['MAE Test']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les prédictions vs valeurs réelles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test_reg, y_pred_reg_meilleur, alpha=0.5, s=10)\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "            [y_test_reg.min(), y_test_reg.max()], \n",
    "            'r--', lw=2)\n",
    "axes[0].set_xlabel('Valeurs Réelles')\n",
    "axes[0].set_ylabel('Prédictions')\n",
    "axes[0].set_title(f'Prédictions vs Valeurs Réelles - {meilleur_modele_reg_nom}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Résidus\n",
    "residus = y_test_reg - y_pred_reg_meilleur\n",
    "axes[1].scatter(y_pred_reg_meilleur, residus, alpha=0.5, s=10)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Prédictions')\n",
    "axes[1].set_ylabel('Résidus')\n",
    "axes[1].set_title('Analyse des Résidus', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optimisation du Meilleur Modèle avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser le meilleur modèle de classification avec GridSearchCV\n",
    "print(f\"Optimisation du modèle {meilleur_modele_nom} pour la classification...\\n\")\n",
    "\n",
    "# Définir la grille de paramètres selon le modèle\n",
    "if 'Random Forest' in meilleur_modele_nom:\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [8, 10, 12],\n",
    "        'min_samples_split': [10, 20, 30],\n",
    "        'min_samples_leaf': [5, 10, 15]\n",
    "    }\n",
    "elif 'AdaBoost' in meilleur_modele_nom:\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "elif 'Gradient' in meilleur_modele_nom:\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.7, 0.8, 0.9]\n",
    "    }\n",
    "else:\n",
    "    param_grid = {}\n",
    "    print(\"Pas de grille de paramètres définie pour ce modèle\")\n",
    "\n",
    "if param_grid:\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=type(meilleur_modele_cat)(),\n",
    "        param_grid=param_grid,\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_cat_scaled, y_train_cat)\n",
    "    \n",
    "    print(f\"\\nMeilleurs paramètres: {grid_search.best_params_}\")\n",
    "    print(f\"Meilleur score CV: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Évaluer sur le test set\n",
    "    y_pred_optimized = grid_search.predict(X_test_cat_scaled)\n",
    "    score_optimized = accuracy_score(y_test_cat, y_pred_optimized)\n",
    "    \n",
    "    print(f\"Score Test après optimisation: {score_optimized:.4f}\")\n",
    "    print(f\"Amélioration: {score_optimized - comparaison_df.iloc[0]['Score Test']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sauvegarde des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un résumé des résultats\n",
    "resume_resultats = {\n",
    "    'Classification - Catégorie': {\n",
    "        'Meilleur Modèle': meilleur_modele_nom,\n",
    "        'Score Test': comparaison_df.iloc[0]['Score Test'],\n",
    "        'Score CV': comparaison_df.iloc[0]['Score CV (mean)'],\n",
    "        'Surapprentissage': comparaison_df.iloc[0]['Surapprentissage']\n",
    "    },\n",
    "    'Classification - Résiliation': {\n",
    "        'Meilleur Modèle': meilleur_modele_resil_nom,\n",
    "        'Score Test': comparaison_resil_df.iloc[0]['Score Test'],\n",
    "        'Score CV ROC-AUC': comparaison_resil_df.iloc[0]['Score CV ROC-AUC (mean)']\n",
    "    },\n",
    "    'Régression - Montant TTC': {\n",
    "        'Meilleur Modèle': meilleur_modele_reg_nom,\n",
    "        'R2 Test': comparaison_reg_df.iloc[0]['R2 Test'],\n",
    "        'RMSE Test': comparaison_reg_df.iloc[0]['RMSE Test'],\n",
    "        'MAE Test': comparaison_reg_df.iloc[0]['MAE Test']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Résumé des Résultats:\")\n",
    "print(\"=\" * 80)\n",
    "for tache, resultats in resume_resultats.items():\n",
    "    print(f\"\\n{tache}:\")\n",
    "    for metrique, valeur in resultats.items():\n",
    "        print(f\"  {metrique}: {valeur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "import pickle\n",
    "\n",
    "# Sauvegarder les comparaisons\n",
    "comparaison_df.to_csv('resultats_classification_categorie.csv', index=False)\n",
    "comparaison_resil_df.to_csv('resultats_classification_resiliation.csv', index=False)\n",
    "comparaison_reg_df.to_csv('resultats_regression_montant.csv', index=False)\n",
    "\n",
    "print(\"Résultats sauvegardés dans des fichiers CSV\")\n",
    "\n",
    "# Sauvegarder les modèles\n",
    "with open('meilleur_modele_categorie.pkl', 'wb') as f:\n",
    "    pickle.dump(meilleur_modele_cat, f)\n",
    "    \n",
    "with open('meilleur_modele_resiliation.pkl', 'wb') as f:\n",
    "    pickle.dump(meilleur_modele_resil, f)\n",
    "    \n",
    "with open('meilleur_modele_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(meilleur_modele_reg, f)\n",
    "\n",
    "# Sauvegarder les scalers\n",
    "with open('scaler_categorie.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_cat, f)\n",
    "    \n",
    "with open('scaler_resiliation.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_resil, f)\n",
    "    \n",
    "with open('scaler_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_reg, f)\n",
    "\n",
    "print(\"Modèles et scalers sauvegardés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusions et Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "1. **Classification des Catégories de Clients:**\n",
    "   - Le meilleur modèle identifie efficacement les différentes catégories de clients\n",
    "   - Les features les plus importantes sont liées à la consommation et aux montants facturés\n",
    "   - Les techniques d'ensemble (Random Forest, Gradient Boosting) performent généralement mieux\n",
    "\n",
    "2. **Prédiction des Résiliations:**\n",
    "   - L'utilisation de SMOTE améliore significativement la détection des résiliations\n",
    "   - Le déséquilibre des classes a été traité efficacement\n",
    "   - Les modèles peuvent aider à identifier les clients à risque de résiliation\n",
    "\n",
    "3. **Prédiction des Montants:**\n",
    "   - Les modèles de régression fournissent des estimations précises des montants TTC\n",
    "   - La régularisation (Ridge, Lasso, ElasticNet) aide à éviter le surapprentissage\n",
    "   - Les modèles d'ensemble (Random Forest, Gradient Boosting) capturent bien les relations non-linéaires\n",
    "\n",
    "### Recommandations:\n",
    "\n",
    "1. **Pour éviter le surapprentissage:**\n",
    "   - Utiliser la validation croisée systématiquement\n",
    "   - Appliquer la régularisation (L1, L2, ou ElasticNet)\n",
    "   - Limiter la complexité des modèles (max_depth, min_samples_split)\n",
    "   - Utiliser des techniques d'ensemble (bagging, boosting)\n",
    "\n",
    "2. **Pour améliorer les performances:**\n",
    "   - Collecter plus de données sur les résiliations\n",
    "   - Créer de nouvelles features basées sur le domaine métier\n",
    "   - Tester d'autres algorithmes (XGBoost, LightGBM)\n",
    "   - Optimiser les hyperparamètres avec GridSearchCV ou RandomizedSearchCV\n",
    "\n",
    "3. **Pour la mise en production:**\n",
    "   - Monitorer les performances des modèles régulièrement\n",
    "   - Réentraîner les modèles périodiquement avec de nouvelles données\n",
    "   - Mettre en place des alertes pour détecter la dérive des modèles\n",
    "   - Documenter les décisions et les résultats pour la traçabilité\n",
    "\n",
    "### Techniques Anti-Surapprentissage Utilisées:\n",
    "\n",
    "1. **Validation Croisée Stratifiée:** Pour une évaluation robuste des modèles\n",
    "2. **Régularisation:** Ridge, Lasso, ElasticNet pour les modèles linéaires\n",
    "3. **Limitation de la Complexité:** max_depth, min_samples_split, min_samples_leaf\n",
    "4. **Ensemble Methods:** Random Forest, AdaBoost, Gradient Boosting avec subsample\n",
    "5. **Early Stopping:** Implicite dans Gradient Boosting\n",
    "6. **Feature Engineering:** Création de features pertinentes au lieu d'utiliser des features brutes\n",
    "7. **Traitement du Déséquilibre:** SMOTE pour la classification des résiliations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
