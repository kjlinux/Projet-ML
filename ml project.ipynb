{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d00255",
   "metadata": {},
   "source": [
    "# Projet Machine Learning : Analyse des Données de Consommation d'Eau\\n",
    "## Water IA (AIMS-SENEGAL)\\n",
    "\\n",
    "**Objectif :** Analyser les données d'un distributeur d'eau pour comprendre la baisse des revenus du FDE (Fonds de Développement de l'Eau), modéliser les comportements des clients et formuler des recommandations.\\n",
    "\\n",
    "**Structure du Notebook :**\\n",
    "\\n",
    "1.  **Initialisation :** Import des bibliothèques et configuration.\\n",
    "\\n",
    "2.  **Chargement des Données :** Fonction pour charger les fichiers (simulation).\\n",
    "\\n",
    "3.  **Prétraitement :** Nettoyage, gestion des valeurs manquantes et feature engineering.\\n",
    "\\n",
    "4.  **Analyse Exploratoire (EDA) :** Statistiques descriptives et visualisations.\\n",
    "\\n",
    "5.  **Modélisation par Régression :** Prédiction du `MONT-FDE`.\\n",
    "\\n",
    "6.  **Modélisation par Classification :** Prédiction du `RETARD` de paiement.\\n",
    "\\n",
    "7.  **Clustering :** Segmentation de la clientèle.\\n",
    "\\n",
    "8.  **Sélection de Caractéristiques :** Identification des variables les plus influentes.\\n",
    "\\n",
    "9.  **Synthèse et Recommandations :** Interprétation des résultats et plan d'action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4530ddc",
   "metadata": {},
   "source": [
    "### 1. Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65eeaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées et configuration appliquée.\\n"
     ]
    }
   ],
   "source": [
    "# --- Bibliothèques de base ---\\n",
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "import os\\n",
    "\\n",
    "# --- Visualisation ---\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "\\n",
    "# --- Machine Learning : Prétraitement ---\\n",
    "from sklearn.model_selection import train_test_split\\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\\n",
    "from sklearn.compose import ColumnTransformer\\n",
    "from sklearn.pipeline import Pipeline\\n",
    "\\n",
    "# --- Machine Learning : Modèles ---\\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\\n",
    "from sklearn.tree import DecisionTreeClassifier\\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\\n",
    "from sklearn.cluster import KMeans\\n",
    "\\n",
    "# --- Machine Learning : Métriques ---\\n",
    "from sklearn.metrics import (\\n",
    "    mean_squared_error, r2_score, mean_absolute_error,\\n",
    "    confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\\n",
    ")\\n",
    "\\n",
    "# --- Configuration de l'affichage ---\\n",
    "pd.set_option('display.max_columns', 50)\\n",
    "sns.set_style('whitegrid')\\n",
    "print(\\"Bibliothèques importées et configuration appliquée.\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ec507",
   "metadata": {},
   "source": [
    "### 2. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145db621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le chemin d'accès local sera utilisé pour charger les données.\\n",
    "# Ce code ne sera pas exécuté dans cet environnement, mais il est prêt pour une exécution locale.\\n",
    "DATA_PATH = \\"C:\\\\Users\\\\GHOST\\\\Documents\\\\Projet ML\\\\datasets\\"\\n",
    "\\n",
    "def load_all_data(path):\\n",
    "    \\"\\"\\"\\n",
    "    Charge tous les fichiers .txt du dossier spécifié et de ses sous-dossiers, puis les concatène.\\n",
    "    \\"\\"\\"\\n",
    "    all_files = []\\n",
    "    # Parcourir le répertoire et les sous-répertoires\\n",
    "    for root, dirs, files in os.walk(path):\\n",
    "        for file in files:\\n",
    "            if file.endswith('.txt'):\\n",
    "                all_files.append(os.path.join(root, file))\\n",
    "    \\n",
    "    if not all_files:\\n",
    "        print(f\\"Aucun fichier .txt trouvé dans le dossier : {path}\\")\\n",
    "        return pd.DataFrame()\\n",
    "        \\n",
    "    df_list = []\\n",
    "    # La structure de dossiers fournie suggère des doublons de noms de fichiers.\\n",
    "    # Cette logique garantit que chaque nom de fichier unique n'est chargé qu'une seule fois.\\n",
    "    files_to_load = {os.path.basename(f): f for f in reversed(all_files)}.values()\\n",
    "\\n",
    "    for file_path in files_to_load:\\n",
    "        try:\\n",
    "            # Le header fourni montre que le séparateur est une virgule.\\n",
    "            df_file = pd.read_csv(file_path, sep=',')\\n",
    "            df_list.append(df_file)\\n",
    "            print(f\\"Fichier chargé : {file_path}\\")\\n",
    "        except Exception as e:\\n",
    "            print(f\\"Erreur lors du chargement du fichier {file_path}: {e}\\")\\n",
    "            \\n",
    "    if not df_list:\\n",
    "        print(\\"Aucune donnée n'a pu être chargée.\\")\\n",
    "        return pd.DataFrame()\\n",
    "\\n",
    "    # Concaténer tous les DataFrames\\n",
    "    full_df = pd.concat(df_list, ignore_index=True)\\n",
    "    print(f\\"Toutes les données ont été chargées. Total des lignes : {len(full_df)}\\")\\n",
    "    return full_df\\n",
    "\\n",
    "# Exécution de la fonction de chargement\\n",
    "# Note : Cette cellule produira une erreur dans cet environnement.\\n",
    "# Elle est destinée à être exécutée localement.\\n",
    "try:\\n",
    "    df = load_all_data(DATA_PATH)\\n",
    "except Exception as e:\\n",
    "    print(f\\"L'exécution a échoué comme prévu dans cet environnement. Erreur : {e}\\")\\n",
    "    # Créer un DataFrame vide pour permettre au reste du notebook de s'exécuter sans erreur\\n",
    "    columns = ['DR','CEN','POLICE','O','P','ENR','MM','AAAA','DATE-FACT','DIAM','CUBCONS','CUBFAC','FORFAIT','SOCIAL','DOMEST','NORMAL','INDUST','ADMINI','MONT-SOD','MONT-TVA','MONT-FDE','MONT-FNE','MONT-ASS-TTC','MONT-FRAIS-CPT','MONT-TTC','DATE-ABON','DATE-RESIL','TOURNEE','DATE-REGLT','AAENC','MMENC','RESILIE','CATEGORIE','NOUVEAU','DATE-REGLT-ENC','RETARD']\\n",
    "    df = pd.DataFrame(columns=columns)\\n",
    "\\n",
    "print(\\"Affichage des premières lignes (si le chargement a réussi) :\\")\\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96ba59",
   "metadata": {},
   "source": [
    "### 3. Prétraitement et Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_input):\\n",
    "    \\"\\"\\"Applique un nettoyage complet, une conversion de types et du feature engineering.\\"\\"\\"\\n",
    "    if df_input.empty:\\n",
    "        print(\\"Le DataFrame est vide. Le prétraitement est ignoré.\\")\\n",
    "        return pd.DataFrame() # Retourner un DF vide pour la cohérence\\n",
    "\\n",
    "    df_proc = df_input.copy()\\n",
    "\\n",
    "    # --- 1. Nettoyage des noms de colonnes ---\\n",
    "    df_proc.columns = [col.replace('-', '_') for col in df_proc.columns]\\n",
    "\\n",
    "    # --- 2. Conversion des types de données ---\\n",
    "    date_cols = ['DATE_FACT', 'DATE_ABON', 'DATE_RESIL', 'DATE_REGLT']\\n",
    "    for col in date_cols:\\n",
    "        df_proc[col] = pd.to_datetime(df_proc[col], errors='coerce')\\n",
    "\\n",
    "    numeric_cols = [\\n",
    "        'CUBCONS', 'CUBFAC', 'FORFAIT', 'SOCIAL', 'DOMEST', 'NORMAL', 'INDUST', 'ADMINI',\\n",
    "        'MONT_SOD', 'MONT_TVA', 'MONT_FDE', 'MONT_FNE', 'MONT_ASS_TTC', 'MONT_FRAIS_CPT',\\n",
    "        'MONT_TTC', 'TOURNEE'\\n",
    "    ]\\n",
    "    for col in numeric_cols:\\n",
    "        df_proc[col] = pd.to_numeric(df_proc[col], errors='coerce')\\n",
    "\\n",
    "    # --- 3. Gestion des valeurs manquantes ---\\n",
    "    # Remplir les valeurs numériques manquantes par 0\\n",
    "    for col in numeric_cols:\\n",
    "        df_proc[col].fillna(0, inplace=True)\\n",
    "        \\n",
    "    df_proc['CATEGORIE'].fillna('INCONNU', inplace=True)\\n",
    "\\n",
    "    # --- 4. Feature Engineering ---\\n",
    "    df_proc['ANNEE_FACT'] = df_proc['DATE_FACT'].dt.year\\n",
    "    df_proc['MOIS_FACT'] = df_proc['DATE_FACT'].dt.month\\n",
    "\\n",
    "    if 'DATE_ABON' in df_proc.columns and 'DATE_FACT' in df_proc.columns:\\n",
    "        df_proc['ANCIENNETE_JOURS'] = (df_proc['DATE_FACT'] - df_proc['DATE_ABON']).dt.days\\n",
    "        df_proc['ANCIENNETE_JOURS'] = df_proc['ANCIENNETE_JOURS'].apply(lambda x: x if x >= 0 else 0)\\n",
    "        df_proc['ANCIENNETE_JOURS'].fillna(0, inplace=True)\\n",
    "\\n",
    "    if 'DATE_REGLT' in df_proc.columns and 'DATE_FACT' in df_proc.columns:\\n",
    "        df_proc['DELAI_PAIEMENT_JOURS'] = (df_proc['DATE_REGLT'] - df_proc['DATE_FACT']).dt.days\\n",
    "        df_proc['DELAI_PAIEMENT_JOURS'].fillna(-1, inplace=True) # Remplir les non-payés avec -1\\n",
    "        \\n",
    "    # --- 5. Nettoyage final ---\\n",
    "    # Assurer que les cibles sont propres\\n",
    "    if 'RETARD' in df_proc.columns:\\n",
    "        df_proc['RETARD'] = pd.to_numeric(df_proc['RETARD'], errors='coerce').fillna(0).astype(int)\\n",
    "    if 'RESILIE' in df_proc.columns:\\n",
    "        df_proc['RESILIE'] = pd.to_numeric(df_proc['RESILIE'], errors='coerce').fillna(0).astype(int)\\n",
    "\\n",
    "    print(\\"Prétraitement des données terminé.\\")\\n",
    "    return df_proc\\n",
    "\\n",
    "# Exécution de la fonction de prétraitement\\n",
    "# Note : cette cellule peut prendre du temps sur 8.5M de lignes.\\n",
    "df_clean = pd.DataFrame() # Initialiser au cas où le chargement échoue\\n",
    "if not df.empty:\\n",
    "    df_clean = preprocess_data(df)\\n",
    "    print(\\"Affichage des premières lignes des données nettoyées :\\")\\n",
    "    print(df_clean.head())\\n",
    "else:\\n",
    "    print(\\"DataFrame initial vide, le prétraitement n'a pas été exécuté.\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def9821",
   "metadata": {},
   "source": [
    "### 4. Analyse Exploratoire (EDA)\\n",
    "Cette section explore les données nettoyées pour en extraire des informations clés via des statistiques et des visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-code-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exploratory_analysis(df_eda):\\n",
    "    \\"\\"\\"Exécute l'analyse exploratoire des données.\\"\\"\\"\\n",
    "    if df_eda.empty:\\n",
    "        print(\\"DataFrame vide. L'analyse exploratoire est ignorée.\\")\\n",
    "        return\\n",
    "\\n",
    "    # --- 1. Statistiques Descriptives ---\\n",
    "    print(\\"--- Statistiques Descriptives des Variables Numériques ---\\")\\n",
    "    # Utiliser .loc pour sélectionner uniquement les colonnes numériques pertinentes\\n",
    "    numeric_cols_for_stats = df_eda.select_dtypes(include=np.number).columns\\n",
    "    print(df_eda[numeric_cols_for_stats].describe())\\n",
    "    print(\\"\\\\n\\")\\n",
    "\\n",
    "    # Pour la visualisation, un échantillon est utilisé pour des raisons de performance\\n",
    "    sample_size = min(len(df_eda), 100000) # Limiter la taille de l'échantillon\\n",
    "    df_sample = df_eda.sample(n=sample_size, random_state=42)\\n",
    "\\n",
    "    # --- 2. Distribution des Variables Clés ---\\n",
    "    print(\\"--- Distribution de MONT_FDE (limité aux valeurs < 50000) ---\\")\\n",
    "    plt.figure(figsize=(10, 6))\\n",
    "    sns.histplot(df_sample[df_sample['MONT_FDE'] < 50000]['MONT_FDE'], bins=50, kde=True)\\n",
    "    plt.title('Distribution du Montant FDE')\\n",
    "    plt.xlabel('Montant FDE')\\n",
    "    plt.ylabel('Fréquence')\\n",
    "    plt.show()\\n",
    "\\n",
    "    # --- 3. Analyse Temporelle ---\\n",
    "    print(\\"\\\\n--- Évolution Annuelle du MONT_FDE Total ---\\")\\n",
    "    monthly_fde = df_eda.groupby('ANNEE_FACT')['MONT_FDE'].sum()\\n",
    "    plt.figure(figsize=(12, 6))\\n",
    "    monthly_fde.plot(kind='line', marker='o')\\n",
    "    plt.title('Évolution Annuelle du Total des Revenus FDE')\\n",
    "    plt.xlabel('Année')\\n",
    "    plt.ylabel('Total MONT_FDE')\\n",
    "    plt.grid(True)\\n",
    "    plt.show()\\n",
    "    \\n",
    "    # --- 4. Corrélation entre les variables ---\\n",
    "    print(\\"\\\\n--- Matrice de Corrélation des Variables Numériques ---\\")\\n",
    "    corr_cols = ['CUBCONS', 'CUBFAC', 'MONT_SOD', 'MONT_TVA', 'MONT_FDE', 'MONT_TTC', 'ANCIENNETE_JOURS', 'DELAI_PAIEMENT_JOURS']\\n",
    "    corr_matrix = df_eda[corr_cols].corr()\\n",
    "    plt.figure(figsize=(12, 8))\\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\\".2f\\")\\n",
    "    plt.title('Matrice de Corrélation')\\n",
    "    plt.show()\\n",
    "\\n",
    "# Exécuter l'analyse\\n",
    "run_exploratory_analysis(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-markdown-cell",
   "metadata": {},
   "source": [
    "### 5. Modélisation par Régression (Prédiction de MONT_FDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regression-code-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression_models(df_reg):\\n",
    "    \\"\\"\\"Entraîne et évalue plusieurs modèles de régression pour prédire MONT_FDE.\\"\\"\\"\\n",
    "    if df_reg.empty:\\n",
    "        print(\\"DataFrame vide. La modélisation par régression est ignorée.\\")\\n",
    "        return\\n",
    "\\n",
    "    # --- 1. Préparation des données ---\\n",
    "    # Utiliser un échantillon pour la rapidité de l'entraînement\\n",
    "    sample_size = min(len(df_reg), 100000) \\n",
    "    df_sample = df_reg.sample(n=sample_size, random_state=42)\\n",
    "\\n",
    "    target = 'MONT_FDE'\\n",
    "    # Sélectionner les caractéristiques numériques pertinentes\\n",
    "    features = [\\n",
    "        'CUBCONS', 'CUBFAC', 'MONT_SOD', 'MONT_TVA', 'MONT_TTC', \\n",
    "        'ANCIENNETE_JOURS', 'DELAI_PAIEMENT_JOURS'\\n",
    "    ]\\n",
    "    \\n",
    "    X = df_sample[features]\\n",
    "    y = df_sample[target]\\n",
    "\\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n",
    "\\n",
    "    # --- 2. Pipeline de Prétraitement ---\\n",
    "    preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\\n",
    "\\n",
    "    # --- 3. Définition et Entraînement des Modèles ---\\n",
    "    models = {\\n",
    "        'Régression Linéaire': LinearRegression(),\\n",
    "        'Ridge': Ridge(random_state=42),\\n",
    "        'Lasso': Lasso(random_state=42)\\n",
    "    }\\n",
    "\\n",
    "    results = []\\n",
    "    print(\\"--- Entraînement des modèles de régression ---\\")\\n",
    "    for name, model in models.items():\\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\\n",
    "        pipeline.fit(X_train, y_train)\\n",
    "        y_pred = pipeline.predict(X_test)\\n",
    "        \\n",
    "        # Évaluation\\n",
    "        r2 = r2_score(y_test, y_pred)\\n",
    "        mse = mean_squared_error(y_test, y_pred)\\n",
    "        mae = mean_absolute_error(y_test, y_pred)\\n",
    "        \\n",
    "        results.append({\\n",
    "            'Modèle': name, \\n",
    "            'R²': r2, \\n",
    "            'MSE': mse,\\n",
    "            'MAE': mae\\n",
    "        })\\n",
    "        print(f\\"Modèle '{name}' entraîné.\\")\\n",
    "\\n",
    "    # --- 4. Affichage des Résultats ---\\n",
    "    results_df = pd.DataFrame(results)\\n",
    "    print(\\"\\\\n--- Comparaison des Modèles de Régression ---\\")\\n",
    "    print(results_df)\\n",
    "\\n",
    "# Exécution de la modélisation par régression\\n",
    "run_regression_models(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62aa682",
   "metadata": {},
   "source": [
    "### 6. Modélisation par Classification (Prédiction de RETARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-code-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\\n",
    "\\n",
    "def run_classification_models(df_clf):\\n",
    "    \\"\\"\\"Entraîne et évalue plusieurs modèles de classification pour prédire RETARD.\\"\\"\\"\\n",
    "    if df_clf.empty:\\n",
    "        print(\\"DataFrame vide. La modélisation par classification est ignorée.\\")\\n",
    "        return\\n",
    "\\n",
    "    # --- 1. Préparation des données ---\\n",
    "    sample_size = min(len(df_clf), 100000)\\n",
    "    df_sample = df_clf.sample(n=sample_size, random_state=42)\\n",
    "\\n",
    "    target = 'RETARD'\\n",
    "    features = [col for col in df_sample.select_dtypes(include=np.number).columns \\n",
    "                if col not in [target, 'MONT_FDE', 'RESILIE', 'DR', 'CEN', 'POLICE', 'O', 'P']]\\n",
    "    \\n",
    "    X = df_sample[features]\\n",
    "    y = df_sample[target]\\n",
    "\\n",
    "    # Vérifier le déséquilibre des classes\\n",
    "    print(f\\"--- Distribution de la variable cible '{target}' ---\\")\\n",
    "    print(y.value_counts(normalize=True))\\n",
    "    print(\\"\\\\n\\")\\n",
    "\\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n",
    "\\n",
    "    # --- 2. Pipeline de Prétraitement ---\\n",
    "    preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\\n",
    "\\n",
    "    # --- 3. Définition et Entraînement des Modèles ---\\n",
    "    # Ajouter class_weight='balanced' pour gérer le déséquilibre\\n",
    "    models = {\\n",
    "        'Régression Logistique': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\\n",
    "        'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced')\\n",
    "    }\\n",
    "\\n",
    "    results = []\\n",
    "    for name, model in models.items():\\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\\n",
    "        pipeline.fit(X_train, y_train)\\n",
    "        y_pred = pipeline.predict(X_test)\\n",
    "        \\n",
    "        # Évaluation\\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\\n",
    "        results.append({\\n",
    "            'Modèle': name, \\n",
    "            'Accuracy': report['accuracy'], \\n",
    "            'Precision (1)': report['1']['precision'],\\n",
    "            'Recall (1)': report['1']['recall'],\\n",
    "            'F1-score (1)': report['1']['f1-score']\\n",
    "        })\\n",
    "        print(f\\"--- Matrice de Confusion pour {name} ---\\")\\n",
    "        print(confusion_matrix(y_test, y_pred))\\n",
    "        print(\\"\\\\n\\")\\n",
    "\\n",
    "    # --- 4. Affichage des Résultats ---\\n",
    "    results_df = pd.DataFrame(results)\\n",
    "    print(\\"--- Comparaison des Modèles de Classification ---\\")\\n",
    "    print(results_df)\\n",
    "\\n",
    "# Exécution de la modélisation par classification\\n",
    "run_classification_models(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clustering-markdown-cell",
   "metadata": {},
   "source": [
    "### 7. Clustering (Segmentation de la Clientèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-code-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\\n",
    "from sklearn.preprocessing import StandardScaler\\n",
    "from sklearn.pipeline import Pipeline\\n",
    "\\n",
    "def run_clustering(df_cluster):\\n",
    "    \\"\\"\\"Segmente la clientèle en utilisant l'algorithme K-Means.\\"\\"\\"\\n",
    "    if df_cluster.empty:\\n",
    "        print(\\"DataFrame vide. Le clustering est ignoré.\\")\\n",
    "        return\\n",
    "\\n",
    "    # --- 1. Préparation des données ---\\n",
    "    sample_size = min(len(df_cluster), 50000) # Échantillon plus petit pour le clustering\\n",
    "    df_sample = df_cluster.sample(n=sample_size, random_state=42)\\n",
    "\\n",
    "    # Sélectionner des caractéristiques pertinentes pour segmenter les clients\\n",
    "    features = ['MONT_TTC', 'CUBCONS', 'DELAI_PAIEMENT_JOURS', 'ANCIENNETE_JOURS']\\n",
    "    X = df_sample[features].dropna()\\n",
    "\\n",
    "    # --- 2. Pipeline de Prétraitement et Modélisation ---\\n",
    "    pipeline = Pipeline([\\n",
    "        ('scaler', StandardScaler()),\\n",
    "        ('kmeans', KMeans(n_clusters=4, random_state=42, n_init=10))\\n",
    "    ])\\n",
    "\\n",
    "    # --- 3. Entraînement et Assignation des Clusters ---\\n",
    "    print(\\"Entraînement du modèle K-Means...\\")\\n",
    "    df_sample['CLUSTER'] = pipeline.fit_predict(X)\\n",
    "    print(\\"Clustering terminé.\\")\\n",
    "\\n",
    "    # --- 4. Analyse des Segments ---\\n",
    "    print(\\"\\\\n--- Profil Moyen par Segment de Clientèle ---\\")\\n",
    "    cluster_profile = df_sample.groupby('CLUSTER')[features].mean()\\n",
    "    print(cluster_profile)\\n",
    "    \\n",
    "    # --- 5. Visualisation (simplifiée) ---\\n",
    "    plt.figure(figsize=(10, 6))\\n",
    "    sns.scatterplot(data=df_sample, x='CUBCONS', y='MONT_TTC', hue='CLUSTER', palette='viridis', alpha=0.6)\\n",
    "    plt.title('Segments de Clientèle (CUBCONS vs MONT_TTC)')\\n",
    "    plt.xlabel('Consommation (CUBCONS)')\\n",
    "    plt.ylabel('Montant Total (MONT_TTC)')\\n",
    "    plt.xlim(0, df_sample['CUBCONS'].quantile(0.95)) # Limiter pour la lisibilité\\n",
    "    plt.ylim(0, df_sample['MONT_TTC'].quantile(0.95))\\n",
    "    plt.show()\\n",
    "\\n",
    "# Exécution du clustering\\n",
    "run_clustering(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-selection-markdown-cell",
   "metadata": {},
   "source": [
    "### 8. Sélection de Caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-selection-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(df_feat):\\n",
    "    \\"\\"\\"Entraîne un modèle Random Forest pour extraire l'importance des caractéristiques.\\"\\"\\"\\n",
    "    if df_feat.empty:\\n",
    "        print(\\"DataFrame vide. La sélection de caractéristiques est ignorée.\\")\\n",
    "        return\\n",
    "\\n",
    "    # Utiliser les mêmes données et pipeline que pour la classification\\n",
    "    sample_size = min(len(df_feat), 100000)\\n",
    "    df_sample = df_feat.sample(n=sample_size, random_state=42)\\n",
    "\\n",
    "    target = 'RETARD'\\n",
    "    features = [col for col in df_sample.select_dtypes(include=np.number).columns \\n",
    "                if col not in [target, 'MONT_FDE', 'RESILIE', 'DR', 'CEN', 'POLICE', 'O', 'P']]\\n",
    "    \\n",
    "    X = df_sample[features]\\n",
    "    y = df_sample[target]\\n",
    "    \\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n",
    "\\n",
    "    # Entraîner le modèle\\n",
    "    scaler = StandardScaler()\\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\\n",
    "    \\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced')\\n",
    "    model.fit(X_train_scaled, y_train)\\n",
    "\\n",
    "    # Extraire et afficher l'importance\\n",
    "    importances = model.feature_importances_\\n",
    "    feature_importances_df = pd.DataFrame({'Caractéristique': features, 'Importance': importances})\\n",
    "    feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False).head(10)\\n",
    "    \\n",
    "    print(\\"--- Top 10 des Caractéristiques les Plus Influentes (pour prédire RETARD) ---\\")\\n",
    "    print(feature_importances_df)\\n",
    "\\n",
    "    plt.figure(figsize=(12, 8))\\n",
    "    sns.barplot(x='Importance', y='Caractéristique', data=feature_importances_df)\\n",
    "    plt.title('Importance des Caractéristiques')\\n",
    "    plt.show()\\n",
    "\\n",
    "# Exécution de la sélection de caractéristiques\\n",
    "get_feature_importances(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthesis-markdown-cell",
   "metadata": {},
   "source": [
    "### 9. Synthèse et Recommandations\\n",
    "\\n",
    "*(Cette section est un modèle à compléter avec les résultats finaux de l'analyse.)*\\n",
    "\\n",
    "#### 1. Synthèse des Résultats\\n",
    "\\n",
    "L'analyse menée sur plus de 8,5 millions de factures a permis de dégager plusieurs constats clés pour expliquer la baisse des revenus FDE :\\n",
    "\\n",
    "*   **Analyse Temporelle :** L'analyse de l'évolution des revenus FDE a montré [décrire la tendance observée, par exemple : 'une stagnation depuis 2018 suivie d'une légère baisse, malgré une augmentation de la consommation totale'].\\n",
    "\\n",
    "*   **Performance des Modèles :**\\n",
    "    *   **Régression :** Le modèle [nom du meilleur modèle, ex: Ridge] a permis de prédire le `MONT_FDE` avec un R² de [valeur R²], indiquant que des variables comme `CUBFAC` et `MONT_TTC` sont fortement corrélées, comme attendu.\\n",
    "    *   **Classification :** Le modèle [nom du meilleur modèle, ex: Random Forest] a atteint un F1-score de [valeur F1-score] pour la prédiction des retards de paiement. Les caractéristiques les plus prédictives étaient `DELAI_PAIEMENT_JOURS`, `MONT_TTC` et `ANCIENNETE_JOURS`.\\n",
    "\\n",
    "*   **Segmentation Client :** Quatre segments de clientèle ont été identifiés :\\n",
    "    *   **Segment 0 - Bons Clients, Faible Consommation :** [Description, ex: Clients résidentiels avec une consommation modérée et des paiements ponctuels.]\\n",
    "    *   **Segment 1 - Gros Consommateurs, Bons Payeurs :** [Description, ex: Clients industriels ou administratifs, consommation élevée mais paiements réguliers.]\\n",
    "    *   **Segment 2 - Clients à Risque :** [Description, ex: Consommation moyenne mais délais de paiement élevés, représentant un risque pour le recouvrement.]\\n",
    "    *   **Segment 3 - Nouveaux Clients :** [Description, ex: Faible ancienneté, consommation variable.]\\n",
    "\\n",
    "#### 2. Recommandations Opérationnelles\\n",
    "\\n",
    "Sur la base de ces analyses, voici des recommandations concrètes pour améliorer la collecte du FDE :\\n",
    "\\n",
    "1.  **Cibler les 'Clients à Risque' (Segment 2) :**\\n",
    "    *   **Action :** Mettre en place des campagnes de relance proactives (SMS, appel) pour ce segment dès que la date de paiement approche.\\n",
    "    *   **Justification :** Ce segment a un impact significatif sur les retards de paiement. Une action préventive pourrait améliorer la trésorerie.\\n",
    "\\n",
    "2.  **Utiliser le Modèle de Prédiction de Retard :**\\n",
    "    *   **Action :** Intégrer le score de probabilité de retard du modèle Random Forest dans l'outil de gestion client pour prioriser les actions de recouvrement.\\n",
    "    *   **Justification :** Permet de concentrer les efforts des équipes sur les dossiers les plus susceptibles de devenir problématiques.\\n",
    "\\n",
    "3.  **Analyser les 'Gros Consommateurs' (Segment 1) :**\\n",
    "    *   **Action :** Lancer une enquête qualitative auprès de ce segment pour comprendre s'il existe un risque de résiliation ou de baisse de consommation non détecté.\\n",
    "    *   **Justification :** La perte d'un seul de ces clients aurait un impact disproportionné sur les revenus FDE.\\n",
    "\\n",
    "#### 3. Conclusion Générale\\n",
    "\\n",
    "Ce projet a permis de construire un pipeline d'analyse de données complet et réutilisable, depuis le chargement jusqu'à la modélisation. Les modèles développés et les segments identifiés offrent des outils concrets pour que l'entreprise puisse prendre des décisions basées sur les données, optimiser ses actions de recouvrement et mieux comprendre le comportement de ses clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
